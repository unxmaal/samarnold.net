---
title: On the Value of Software
author: Sam
type: post
date: 2016-05-18T13:11:13+00:00
draft: true
url: /?p=45
categories:
  - Uncategorized

---
<div>
  <p>
    I have had the privilege of working for several technology companies and am an avid consumer of tech news and research. While going through training at my tech sales job recently, I found myself breaking down the value of our software to such a fundamental level that I believe it applies to all other software. This feels like a breakthrough to me and I was excited to adapt the resulting framework into the following post and share. I haven&#8217;t seen anything like this, not even during my time at Gartner, and hope to continue to iterate on this and end with a helpful rubric with which to describe any software company&#8217;s value, market fit, and likelihood of success.
  </p>
  
  <p>
    <strong>Sam&#8217;s Software Value Framework</strong>
  </p>
  
  <p>
    <em>All good software is sufficient at each of the following, and uniquely excellent at a few:</em>
  </p>
  
  <p>
    1. Collecting data<br /> 2. Making the data accessible<br /> 3. Appending opinionated insights<br /> 4. Facilitating actions<br /> 5. Measuring results
  </p>
  
  <p>
    <strong>1. Collecting data</strong>
  </p>
  
  <p>
    This may be relatively easy in the case of something like Microsoft Office where it is just user input (though I bet MS developers would quickly correct me on how easy that actually is), but this step alone can be very very hard in other cases such as Business Intelligence tools where data sources are varied, data cleanliness is an issue, many APIs must be created, and so on. The easy way out that too many companies take is to insist that their customers do things their way, that they package data for the convenience of their software, on only most-preferred platforms, and proudly disallow all but the lowest-touch of buyers. Folly!
  </p>
  
  <p>
    <strong>2. Making the Data Accessible<br /> </strong><br /> This is all about taking the data that&#8217;s been collected and turning it into something humans can use. Usually this means providing summaries, visualizations, customizable dashboards, and so on. Sometimes it&#8217;s merely aggregating data that exists in disparate places, or moving data from one place or places to another (ex. API, machine-to-machine). Regardless, there are always major transformations happening to the collected data to make it more usable and they should be the right ones.
  </p>
  
  <p>
    <strong>3. Appending Opinionated Insights</strong>
  </p>
  
  <p>
    This is usually the key value that&#8217;s trumped up the most in software, particularly by founders pitching VCs, as it&#8217;s often the only value based on something that can be patented: machine-learning algorithms, proprietary methodologies, benchmarking based on owned data, etc. It&#8217;s also the thing most likely to impress non-technical people, so you see marketing over-emphasize it in ads & collateral. Not just because marketers are often non-technical themselves, but because their ultimate buyers aren&#8217;t technical or are otherwise unmoved by the inconveniences of their reports.
  </p>
  
  <p>
    As many salespeople can tell you, the degree to which these so-called &#8220;algorithms&#8221; and &#8220;benchmarks&#8221; are any good varies widely, and most of the time they lean on less sexy features like ease of use or platform flexibility to win deals.
  </p>
  
  <p>
    Now that I&#8217;ve torn down the value of opinionated insights, let me build it up again. When software gets this piece right, it is REALLY valuable. Paradigm-shifting even. The reason for this is that the value of a good insight is basically 90% the value of an employee. Or at scale, many employees. Software is expected take in input and provide output&#8211;adding a layer of intelligence that would otherwise take significant human time, effort and knowledge to reproduce is the Holy Grail of technology. It just needs to be real.
  </p>
  
  <p>
    Before I move on, note the word &#8220;opinionated&#8221; again here because it&#8217;s important and overlooked. ANY given insight that a software produces is actually an opinion held by the software company. They have chosen to include some kinds of data, not include others, decided where accuracy is worthwhile vs. where it is not, how to define key terms, etc.&#8211;a series of decision points that are not obvious, not objective, and must be decided for even the simplest-sounding of insights. The result can be a truly strategic differentiator for the company, and it&#8217;s up to marketing & sales to convince the rest of the world that their company&#8217;s opinion is the best one.
  </p>
  
  <p>
    <strong>4. Facilitating Actions</strong>
  </p>
  
  <p>
    It could be argued that everything so far is somehow making actions easier eventually, but truly bridging the gap between data, insights, and acting upon them warrants its own number. The form this takes in practice is, like the rest, varied by use case. Some software is scant in this area on purpose, and may only generate reports or connect to other tools via API that themselves make the actions happen. At the other extreme (such as the tools that API would connect to) there is software that heavily emphasize actions and de-emphasize the data behind them (think end-user systems like email, payroll, helpdesk).
  </p>
  
  <p>
    Ease of use is paramount here. I have won deals against competitors based on the Other Company&#8217;s user interface being slightly weird&#8230; and I have lost them for the same reason. I believe this is a giant hurdle for many companies due simply to the disconnect between developers and end users, who have jobs that couldn&#8217;t be more different than their own. That, and user testing is painful and slow, so it&#8217;s avoided.
  </p>
  
  <p>
    <strong>5. Measuring Results</strong>
  </p>
  
  <p>
    This is non-trivial and must be there, even for tools that don&#8217;t directly handle #4. Aside from the obvious value of &#8220;knowing more = better,&#8221; there&#8217;s an interesting Darwinian selection process going on here. Consider: if there are two pieces of software with the same purpose, where one of them shows you how good they are, and the other lets you figure it out for yourself, which one is going to be better at retention? Which one probably has better case studies on the outcomes they provide? If the original buyer gets fired, who has an easier story to tell to their replacement? I have a radical belief here that even if one software product is much better than another, the added security of knowing exactly HOW bad the latter is provides added security that makes them the preferable choice to most buyers. Software that can&#8217;t measure the results of using it is like a lion with dull claws: doomed to extinction.
  </p>
  
  <p>
    <strong>Next steps&#8230;</strong>
  </p>
  
  <p>
    I would like to continue to develop these thoughts into more complete guide with real-world case studies and practical ideas for how to apply these lessons to different jobs, particularly in sales. Any thoughts or criticisms are supremely welcome!
  </p>
</div>